{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt # Plotting library\n",
    "import numpy as np # Algebra library\n",
    "# import tensorflow as tf # Tensorflow\n",
    "import tensorflow.compat.v1 as tf # Tensorflow\n",
    "import os # Folder management library\n",
    "import pandas as pd # Essentially puts data in spreadsheeet\n",
    "#from PIL import Image # Image processing library\n",
    "import scipy.misc # General stats functions\n",
    "import random # Pseudo random number generator\n",
    "from sklearn.model_selection import train_test_split # To split data into train, test, validation\n",
    "import pickle # Serializing module.\n",
    "from matplotlib.image import imread # Plotting images\n",
    "\n",
    "# New libraries ------------------------------------------------------------\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.initializers import glorot_uniform\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "import tensorflow as tf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print tensorflow version\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "\n",
    "strategy = tf2.distribute.MirroredStrategy()\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available CPUs and GPUs on Machine\n",
    "Just shows what devices are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data for Training, Validation, and Testing \n",
    "Run this cell if you will be training the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read data from disk. X contains images, and y contains labels.\n",
    "X_unpickle = open('X_new.pickle', 'rb')\n",
    "y_unpickle = open('y_new.pickle', 'rb')\n",
    "\n",
    "# load the unpickle object into a variable\n",
    "X = pickle.load(X_unpickle)\n",
    "y = pickle.load(y_unpickle)\n",
    "\n",
    "# Split data into train, validation, test\n",
    "# Stratify with respect to y so that there is an even number of 1s and 0s in each set.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=50/350, random_state=42, stratify=y)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=50/300, random_state=42, stratify=y_train)\n",
    "# Convert lists to numpy arrays\n",
    "X_train, X_test, X_val = np.array(X_train).astype(\"float32\"), np.array(X_test).astype(\"float32\"), np.array(X_val).astype(\"float32\")\n",
    "y_train, y_test, y_val = np.array(y_train).astype(\"float32\"), np.array(y_test).astype(\"float32\"), np.array(y_val).astype(\"float32\")\n",
    "\n",
    "print('Training Set (No. imgs, length, width) and Labels (No. imgs):', X_train.shape, y_train.shape)\n",
    "print('Validation Set (No. imgs, length, width) and Labels (No. imgs):', X_val.shape, y_val.shape)\n",
    "print('Test Set (No. imgs, length, width) and Labels (No. imgs):', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 11))\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1, 5, i)\n",
    "    sample_image = X_train[i]\n",
    "    plt.imshow(sample_image, cmap='gray')\n",
    "    plt.title(y_train[i])\n",
    "    plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "\n",
    "\n",
    "    # FUNCTIONS ------------------------------------------------------------------------------------------------------------\n",
    "    class predictions(tf.keras.layers.Layer):\n",
    "\n",
    "        def __init__(self, caps_Lminus1, dims_Lminus1, caps_L, dims_L, name=None):\n",
    "            super(predictions, self).__init__()\n",
    "            init_sigma = 0.1\n",
    "            W_init = tf.random_normal(shape=(1, caps_Lminus1, caps_L, dims_L, dims_Lminus1),\n",
    "                                      stddev=init_sigma, dtype=tf.float32, name=\"W_init\")            \n",
    "            self.W = tf.Variable(W_init, name=\"W\")\n",
    "            \n",
    "\n",
    "        def call(self, inputs, **kwargs):\n",
    "            output_Lminus1, batch_size, weight_sharing, grid_cells_Lminus1, caps_L = inputs\n",
    "\n",
    "            if tf.get_static_value(weight_sharing) == False:\n",
    "                output_Lminus1 = tf.squeeze(output_Lminus1, axis=[1, 4], name=\"output_Lminus1\")\n",
    "                \n",
    "            # Tile W for the batch\n",
    "            W_tiled = tf.tile(self.W, [batch_size, grid_cells_Lminus1, 1, 1, 1], name=\"W_tiled\")\n",
    "            # -1 means add another dimension to the end of tensor\n",
    "            output_expanded_Lminus1 = tf.expand_dims(output_Lminus1, -1, name=\"output_expanded_Lminus1\")\n",
    "            # 2 means add another dimension to the 2th position of tensor\n",
    "            output_tile_Lminus1 = tf.expand_dims(output_expanded_Lminus1, 2, name=\"output_tile_Lminus1\")\n",
    "            # 1 in shape argument means keep dimensions from caps1_output_tile\n",
    "            output_tiled_Lminus1 = tf.tile(output_tile_Lminus1, [1, 1, caps_L, 1, 1], name=\"output_tiled_Lminus1\")\n",
    "            # Get prediction tensor (3rd array) by using t.matmul\n",
    "            predicted_L = tf.matmul(W_tiled, output_tiled_Lminus1, name=\"predicted_L\")\n",
    "\n",
    "            return predicted_L\n",
    "\n",
    "\n",
    "    def routing(caps_Lminus1, caps_L, batch_size, iterations, predicted_L, name=None):\n",
    "\n",
    "        with tf.name_scope(name, default_name=\"routing\"):\n",
    "            # initialize the raw routing weights to zero\n",
    "            # The two extra 1s is so that raw_weights and weighted_predictions have the same size\n",
    "            raw_weights = tf.zeros([batch_size, caps_Lminus1, caps_L, 1, 1], dtype=tf.dtypes.float32, name=\"raw_weights\")\n",
    "\n",
    "            for r in range(0, iterations):\n",
    "\n",
    "                # c_i = softmax(b_i)\n",
    "                routing_weights = tf.nn.softmax(raw_weights, dim=2, name=\"routing_weights\")\n",
    "                # weighted sum of all the predicted output vectors for each second-layer capsule\n",
    "                weighted_predictions = tf.multiply(routing_weights, predicted_L, name=\"weighted_predictions\")\n",
    "                weighted_sum = tf.reduce_sum(weighted_predictions, axis=(1), keepdims=True, name=\"weighted_sum\")\n",
    "\n",
    "                # Squash weighted_sum (s_j) to get output for 2nd capsules (v_j)\n",
    "                output_L = squash(weighted_sum, axis=-2, name=\"output_L\")\n",
    "\n",
    "                # Make caps2_output same size as predicted_caps\n",
    "                output_tiled_L = tf.tile(output_L, \n",
    "                                             [1, caps_Lminus1, 1, 1, 1], \n",
    "                                             name=\"output_tiled_L\")\n",
    "                # the 1 in the shape argument in tf.tile means keep dimension from caps2_output.\n",
    "\n",
    "                # Dot Product\n",
    "                agreement = tf.matmul(predicted_L, output_tiled_L, transpose_a=True, name=\"agreement\")\n",
    "                # Update raw_weights\n",
    "                raw_weights = tf.add(raw_weights, agreement, name=\"raw_weights\")\n",
    "\n",
    "            return output_L, routing_weights\n",
    "\n",
    "    # safe_norm taken from Aurélien Geron\n",
    "    def squash(s, axis=-1, epsilon=1e-7, name=None):\n",
    "\n",
    "        with tf.name_scope(name, default_name=\"squash\"):\n",
    "            squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                         keepdims=True)\n",
    "            safe_norm = tf.sqrt(squared_norm + epsilon)\n",
    "            squash_factor = squared_norm / (1. + squared_norm)\n",
    "            unit_vector = s / safe_norm\n",
    "            return squash_factor * unit_vector\n",
    "\n",
    "\n",
    "    # safe_norm taken from Aurélien Geron\n",
    "    def safe_norm(s, axis=-1, epsilon=1e-7, keep_dims=False, name=None):\n",
    "\n",
    "        with tf.name_scope(name, default_name=\"safe_norm\"):\n",
    "            squared_norm = tf.reduce_sum(tf.square(s), axis=axis,\n",
    "                                         keep_dims=keep_dims)\n",
    "            return tf.sqrt(squared_norm + epsilon)\n",
    "        \n",
    "    # THE CAPSULE NETWORK ARCHITECTURE ----------------------------------------------------------------------------------            \n",
    "    #input ---------------------------------------------------------------------\n",
    "    X = layers.Input(shape=(None, None, 1), dtype=tf.float32, name=\"X\") \n",
    "    y = layers.Input(shape=[None], dtype=tf.float32, name=\"y\")\n",
    "    \n",
    "    # Conv Layer ---------------------------------------------------------------\n",
    "    conv1 = layers.Conv2D(filters=16, kernel_size=9, strides=(3,3), \n",
    "                          padding=\"valid\", activation='relu')(X)\n",
    "    \n",
    "    # Convcaps Layer -----------------------------------------------------------\n",
    "    # No. of dimenions a single capsule contains.\n",
    "    convcaps_dims = 8 \n",
    "    # No. of capsules per grid cell.\n",
    "    convcaps_caps_types = 32 \n",
    "    convcaps = layers.Conv2D(filters=convcaps_caps_types*convcaps_dims, kernel_size=5, strides=(2,2), \n",
    "                             padding=\"valid\", activation='relu')(conv1)\n",
    "    # Length and width of convaps layer.\n",
    "    convcaps_grid_length = tf.shape(convcaps)[1]   \n",
    "    convcaps_grid_width = tf.shape(convcaps)[2] \n",
    "    convcaps_grid_cells = convcaps_grid_length * convcaps_grid_width\n",
    "    # Total No. capsules in convcaps layer.\n",
    "    convcaps_caps = convcaps_caps_types * convcaps_grid_cells\n",
    "    # Reshape convcaps so that it is easier to work with.\n",
    "    convcaps_reshape = tf.reshape(convcaps, [-1, convcaps_caps, convcaps_dims], name=\"convcaps_reshape\")\n",
    "    # Squash convcaps with squashing function.\n",
    "    convcaps_output = squash(convcaps_reshape, name=\"convcaps_output\")\n",
    "    \n",
    "\n",
    "    \n",
    "    # First Capsule Layer-------------------------------------------------------\n",
    "    # The batch size\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    caps1_caps = 24\n",
    "    caps1_dims = 12\n",
    "    caps1_predictions = predictions(convcaps_caps_types, convcaps_dims, \n",
    "                                    caps1_caps, caps1_dims, \"caps1_predictions\")([convcaps_output, batch_size, True, convcaps_grid_cells, caps1_caps])\n",
    "    caps1_output, routing1 = routing(convcaps_caps, caps1_caps, \n",
    "                                      batch_size, 9, caps1_predictions, \"routing1\")\n",
    "    \n",
    "    # Second Capsule Layer ------------------------------------------------------\n",
    "    caps2_caps = 8\n",
    "    caps2_dims = 16\n",
    "    caps2_predictions = predictions(caps1_caps, caps1_dims, \n",
    "                                    caps2_caps, caps2_dims, \"caps2_predictions\")([caps1_output, batch_size, False, 1, caps2_caps])\n",
    "    caps2_output, routing2 = routing(caps1_caps, caps2_caps, batch_size, 9, caps2_predictions, \"routing2\")\n",
    "\n",
    "\n",
    "    # Third Capsule Layer --------------------------------------------------------\n",
    "    caps3_caps = 1\n",
    "    caps3_dims = 16\n",
    "\n",
    "    caps3_predictions = predictions(caps2_caps, caps2_dims, \n",
    "                                    caps3_caps, caps3_dims, \"caps3_predictions\")([caps2_output,  batch_size, False, 1, caps3_caps])\n",
    "\n",
    "    caps3_output, routing3 = routing(caps2_caps, caps3_caps, batch_size, 9, caps3_predictions, \"routing3\")\n",
    "    \n",
    "    \n",
    "    # Capsule Accuracy ----------------------------------------------------------\n",
    "    # Lengths of capsules represent probability that entity exists.\n",
    "    lengths = safe_norm(caps3_output, axis=-2, name=\"lengths\")\n",
    "    # Round lengths to determine predicted class.\n",
    "    lengths_rounded = tf.round(lengths, name=\"lengths_rounded\")\n",
    "    # Remove dimensions of size 1 from lengths_rounded\n",
    "    y_predictions = tf.squeeze(lengths_rounded, axis=[1,2,3], name=\"y_predictions\")\n",
    "\n",
    "    # If y matches y_predictions than 1 otherwise 0.\n",
    "    correct = tf.equal(y, y_predictions, name=\"correct\")\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32), name=\"accuracy\")\n",
    "    \n",
    "    \n",
    "    # Custom loss----------------------------------------------------------------\n",
    "    def my_loss_fn(y_true, y_pred):\n",
    "        m_plus = 0.9\n",
    "        m_minus = 0.1\n",
    "        lambda_ = 0.5\n",
    "\n",
    "        T = tf.reshape(y_true, shape=[-1, 1], name=\"T\")\n",
    "        # Compute norm of each capsule in digitcaps\n",
    "        caps3_output_norm = safe_norm(y_pred, axis=-2, keep_dims=True, name=\"caps3_output_norm\")\n",
    "\n",
    "        present_error_raw = tf.square(tf.maximum(0., m_plus - caps3_output_norm), name=\"present_error_raw\")\n",
    "        present_error = tf.reshape(present_error_raw, shape=(-1, caps3_caps), name=\"present_error\")\n",
    "        # -1 tells reshape to calculate the size of this dimension. \n",
    "\n",
    "        absent_error_raw = tf.square(tf.maximum(0., caps3_output_norm - m_minus), name=\"absent_error_raw\")\n",
    "        absent_error = tf.reshape(absent_error_raw, shape=(-1, caps3_caps), name=\"absent_error\")\n",
    "        # -1 tells reshape to calculate the size of this dimension. \n",
    "\n",
    "        # Compute Margin Loss\n",
    "        L = tf.add(T * present_error, lambda_ * (1.0 - T) * absent_error, name=\"L\")\n",
    "        loss = tf.reduce_mean(tf.reduce_sum(L, axis=1), name=\"loss\")\n",
    "        tf.summary.scalar('loss', loss)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    \n",
    "    # Optimizer ---------------------------------------------------------------\n",
    "    model = Model(X, caps3_output)\n",
    "    opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "    model.compile(optimizer=opt, loss=my_loss_fn)\n",
    "    \n",
    "    \n",
    "    # Callback -----------------------------------------------------------------------\n",
    "    val_temp_path = './val_temp1.pickle'\n",
    "    if os.path.isfile(val_temp_path):\n",
    "        val_temp = open(val_temp_path, 'rb')\n",
    "        val_temp = pickle.load(val_temp)\n",
    "    else:\n",
    "        val_temp = 10\n",
    "\n",
    "    class custom(keras.callbacks.Callback):\n",
    "        def on_epoch_end(self, epoch, logs={}):\n",
    "            global val_temp\n",
    "            val = logs.get('val_loss')\n",
    "            if val < val_temp:\n",
    "                val_temp = val\n",
    "                print(' ')\n",
    "                print(val_temp, \"SAVING\")\n",
    "\n",
    "                with open(val_temp_path, 'wb') as handle:\n",
    "                    pickle.dump(val_temp, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "                model.save_weights('./new_weights.h5')\n",
    "    \n",
    "\n",
    "    # Load weights --------------------------------------------------------------------------\n",
    "    model.load_weights('./model/my_capsule_network.h5')    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train the Architecture\n",
    "Run the below cell if you would like to train the architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, batch_size=5, epochs=1000, validation_data=(X_val, y_val), callbacks=[custom()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=10)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Number of Trainable Weights in Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
